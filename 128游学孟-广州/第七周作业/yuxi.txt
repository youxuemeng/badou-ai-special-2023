什么是神经网络？

神经网络的阶段？
1.接收来自其他n个神经元传递过来的信号，这些输入信号通过与相对应的权重进行加权求和传递给下个阶段。（预激活阶段）
2.把预激活的加权结果传递给激活函数

什么是神经网络？
它由相互联系的神经元形成，这些神经具有权重和在网络训练期间根据错误来进行更新的偏差，目标是找到一个未知函数的近似值。
输入：特征向量
权重：特征值
激活函数：

sigmoid函数
tanh函数
ReLU函数

神经元稀疏ReLU函数其实是分段线性函数，把所有的负值都变为0，而正值不变，这种操作被称为单侧抑制。

张量

设计神经网路
1.使用神经网络训练数据之前，必须确定神经网络的层数，以及每层单元的个数
2.特征向量在被传入输入层时通常要先标准化到0-1之间
3.离散型变量可以编码成每一个输入单元对应一个特征指可能赋的值（疑惑）
4.神经网络既可以用来做分类问题，也可以解决回归问题

什么是深度学习
深度神经网络&深度学习
传统的神经网络发招了多隐藏层的情况
具有多个隐藏层的神经网络被称为深度神经网络，基于深度神经网络的机器下学习研究称之为深度学习。
监督学习与非监督学习
有监督学习：输入的数据被称为训练数据，一个模型需要经过一个驯良过程，在这个过程中进行预期判断，如果错误了再进行修正，训练过程
抑制持续到基于训练数据达到预期的精确性。其关键方法是分类和回归。比如逻辑回归和BP神经网络。
无监督学习：没有任训练数据，基于没有标记的输入数据采取推导结构的模型，其关键方式是关联规则学习和聚合，比如k-means

训练（Training）:一个初始网络通过不断地优化自身参数，来让自己变得准确。这整个过程就称之为训练。
推理（Inference）:你训练你好了一个模型，在训练数据集中表现良好，但是我们地期望是可以对以前没看过地图片进行识别。你重新拍一张图片
扔进网络让网络做判断，这种图片就叫做现场数据。

优化：是指调节模型以在训练数据上得到最佳性能（即机器学习中的学习）。
泛化：指训练好的模型在前所未见的数据上的性能好坏。

数据集分类：
1.训练集：实际训练算法的数据集；用来计算梯度，并确定每次迭代中网络权值的更新；
2.验证集：用于跟踪其学习效果的数据集；是一个指示器，用来表明训练数据点之间所形成的网络函数发生了什么，并且验证集上的误差值在整个训练
过程中都将被检测
3.测试集：用于产生最终结果的数据集。

BP网络：一种按误差逆向传播算法训练的多层前馈网络，用于函数逼近，模型识别分类，数据压缩和时间序列预测等。

训练（学习）过程：
正向传播
输入信号从输入层经过各个隐藏层像输出层传播。在输出层得到实际的响应值，若实际值与期望值误差较大，就会转入误差反向传播阶段。
反向传播
按照梯度下降的方法从输出层经过各个隐含层并逐层不断地调整各神经元的连接权值和阈值，反复迭代，直到网络输出的误差减少到可以接受的
程度，或者进行到预先设定的学习次数。

神经网络的训练
一代训练
一批数据
一次迭代

神经网络的训练过程
1.提取特征向量作为输入。
2.定义神经网络结构。包括隐藏层数，激活函数登等。
3.通过训练利用反向传播算法不断优化权重的值，使之达到最合理的水平。
4.使用训练好的神经网络来预测未知数据（推理），这里训练好的网络就是指权重达到最优的情况。

1.选择样本集合的一个样本(Ai,Bi)，Ai为数据，Biw为标签（所属类别）
2.送入网络，计算网络的实际输出Y，（此时网络中的权重应该都是随机量）
3.计算D=Bi - Y(即预测值与实际值相差多少)
4.根据误差D调整权重矩阵W
5.对每个样本重复上述过程，直到对整个样本集来说，误差不超过规定范围。

1.参数的随机初始化
2.前向传播计算每个样本对应的输出节点激活函数值
3.计算损失函数
4，反向传播计算偏导数
5.使用梯度下降或先进的优化方法更新权值

损失函数
均值平方差
交叉熵：表示预测输入样本属于哪一类的概率
损失函数的选取取决于输入标签数据的类型：
1.如果输入的实数，无界的值，损失函数使用MSE。
2.如果输入标签是为矢量（分类标志），使用交叉熵会更适合。

梯度下降法
学习率
新权值 = 当前权值 - 学习率*梯度

泛化能力分类
*欠拟合：模型没有能够很好的表现出数据的结构，而出现的拟合度不高的情况。模型不能在训练集上获得足够低的误差。
*拟合：测试误差与训练误差差距较小；
*过拟合：模型过分的拟合训练样本，但对测试样本预测准率不高的情况，也就是说模型泛化能力很差。训练误差和测试误差之间的差距太大
*不收敛：模型不是根据训练集训练所得到的。
过拟合指的是给定一堆数据，这堆数据带有噪声，利用模型去拟合这堆数据，可能会把噪声数据也给拟合了。
*一方面会造成模比较复杂；
*另一方面，模型的泛化性能太差，遇到新的数据，用得到的过拟合的模型，正确率是很差的。

出现的原因：
1.建模样本选取了错误的选样方法，样本标签等，或样本数量太少，所选取的样本数量不足以代表预定的分类规则，
2.样本噪音干扰过大，使得机器将部分噪音认为是特征从而扰乱了预设的分类规则
3.假设的模型无法合理存在，或者说是无法达到假设成立的条件
4.参数太多导致模型复杂度过高
5.对于神经网络模型:a）对样本数据可能存在分类决策不唯一，随着学习的进行，BP算法使权值可能收敛过于复杂的决策
面；b）权值学习迭代次数足够多，拟合了训练数据中的噪声和训练样例中没有代表性的特征。

过拟合的解决方法：
1.减少特征：删除与目标不相关特征，如一些特征选择方法
2，Early stopping？
3.更多的训练样本。
4.重新清洗数据
5.Dropout？

BP算法是一个迭代算法：
1.将训练集数据输入到神经网络的输入层，经过隐藏层，最后达到输出层并输出结果，这就是前向传播过程。
2.由于神经网路的输出结果与实际姐夫哦有误差，则计算估计值与实际值之间的误差，并将该误差从输出层向隐藏层方向
传播，直至传播到输入层，
3.在反向传播的过程中，根据误差调整各种参数的值（相连神经元的权重），使得总损失函数减小。

BP神经网络
BP算法是一个迭代算法，它得基本思想如下：
1.将训练数据输入到神经网络得输入层，经过隐藏层，最后达到输出层并输出结果，这就是前向传播过程。
2.由于神经网络的输出结果与实际结果有误差，则计算估计值与实际值之间的误差，并将误差从输出层向隐藏层方向传播，直至传播到
输入层。
3，在反向传播的过程中，根据误差调整各种参数的值（相连神经元的权重），使得损失函数减小；


